import streamlit as st
import requests
import json
import os
from dotenv import load_dotenv
from newspaper import Article

st.title('Article Summarizer')
st.markdown('''
           Don't have the time to go through all of the article?
           No Worries! We've got your back.
           Just enter the URL of your favourite articles you want to summarize
           and get through the crux of the matter!
           ''')
st.divider()

# input for URL of the original news article
article_url = st.text_input(label='Article URL')
st.button(label='Submit')

st.divider()

# Creating the Session
session = requests.session()

# Fetching the news from the web
def fetch_article(article_url):
    try:
        # Defining headers
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'
        }
        response = session.get(article_url, headers=headers, timeout=10)
        if response.status_code == 200:
            article = Article(article_url)
            article.download()
            article.parse()
            
            # print(f'Title : {article.title}')
            # print(f'Text : {article.text}')
            return [article.title,article.text]
            
        else:
            print(f'Failed to fetch article at {article_url}')
            
    except Exception as e:
        print(f'Error occured while fetching article at {article_url}: {e}')

if article_url:
    [article_title, article_text] = fetch_article(article_url)
else:
    article_title = 'MIT researchers introduce generative AI for databases'
    article_text = ['MIT researchers have developed GenSQL, a generative AI system for databases that can perform complicated statistical analyses of tabular data without requiring the user to know the underlying processes.',
                    'GenSQL can be used for prediction, anomaly detection, guessing missing values, error correction, or generating synthetic data.',
                    'The system can catch anomalies in specific contexts, such as a low blood pressure reading for a patient who usually has high blood pressure.',
                    'GenSQL integrates a tabular dataset and a generative probabilistic AI model that can account for uncertainty and adjust decision-making based on new data.',
                    'Synthetic data generated by GenSQL can be useful in situations where sensitive data cannot be shared or when real data are sparse.',
                    'GenSQL is built on top of SQL, a programming language for database creation and manipulation, and is designed to be an analogous language for probabilistic models.',
                    'GenSQL outperforms popular AI-based approaches for data analysis in terms of speed and accuracy, and its probabilistic models are explainable.',
                    'The system aims to enable a large set of users to query their data and models without requiring extensive knowledge of the details.']

# Loading the environment variables  
load_dotenv()

# Loading the API KEY for Huggingface from the environment variable
HF_API_KEY = os.environ['HF_API_KEY']

# Importing necessary libraries for News Summarizer
from langchain_huggingface.llms.huggingface_endpoint import HuggingFaceEndpoint
from langchain.prompts.prompt import PromptTemplate
from langchain.output_parsers import PydanticOutputParser
from pydantic import field_validator, BaseModel, Field
from typing import List

# Defining the Pydantic class to be used as ouput parser
class ArticleSummary(BaseModel) : 
    title: str = Field(description="Title of the article")
    summary: List[str] = Field(description="Bulleted list summary of the article")
    
    # Field validator to check if the summary has more then three lines or not. The summary is expected to be of more than three lines.
    @field_validator('summary')
    def check_lines(cls, list_of_lines):
        if len(list_of_lines) < 3:
            raise ValueError("Generated summary has less than three bullet points.")
        return list_of_lines

# Creating the output parser object.
parser = PydanticOutputParser(pydantic_object=ArticleSummary)

# The prompt Template for LLM
propmt_template = PromptTemplate(
    input_variables=['article_title','article_text'],
    template='''
        You are an advanced AI assistant that summarizes online articles.

        Here's the article you want to summarize.

        ==================
        Title: {article_title}

        {article_text}
        ==================

        {format_instructions}
    ''',
    partial_variables={'format_instructions': parser.get_format_instructions()}
)

# The actual prompt to be passed to the LLM

prompt = propmt_template.format(article_title=article_title, article_text=article_text)

# Initializing the LLM via HuggingFace.
# The model used is Mixtral - 7B - Instruct. (A chat Model).
llm = HuggingFaceEndpoint(
    huggingfacehub_api_token=HF_API_KEY,
    repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1',
    temperature=0.2
)

# Extracting the response from the LLM
response = llm.invoke(prompt)

# Parsing the response using the ouput parser.
parsed_response = parser.parse(response)
print(parsed_response)

# Parsed Reponse (Title and the Bullet Points.)
# print(parsed_response.title)
st.header(parsed_response.title)
st.divider()
for item in parsed_response.summary:
    st.write('-',item)